{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python script to extract syllabel and word level embeddings\n",
    "This python script extracts syllable and word level embeddings from the skip-gram models trained on a large scale English popular music lyrics. The trained models can be found in the folder: lyric_encoders. We have trained models for embeddings vector dimens of 10, 50, 100 and 128. Depends on gensim. Install gensim as pip install gensim\n",
    "\n",
    "Date: 01-08-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllModel = Word2Vec.load('./lyric_encoders/syllEncoding_skipgram_2019_05_22_10_dim.bin')\n",
    "wordModel = Word2Vec.load('./lyric_encoders/wordLevelEncoder_skipgram_2019_05_22_10_dim.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "syll_lyrics = ['I', 'love', 'ma', 'chine', 'learn', 'ing']\n",
    "word_lyrics = ['I', 'love', 'machine', 'learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract syllable level embeddings\n",
    "\n",
    "for syll in syll_lyrics:\n",
    "    if syll not in syllModel.wv.vocab:\n",
    "        syll_emb = syllModel.wv['I']\n",
    "        print(syll, syll_emb)\n",
    "    else:\n",
    "        syll_emb = syllModel.wv[syll]\n",
    "        print(syll, syll_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I [-0.04833112  0.1590318  -0.11605258  0.01226982 -0.04435916 -0.04111193\n",
      "  0.22174796 -0.8497301  -0.44738093  0.4237345 ]\n",
      "love [-0.08729718 -0.11972886 -0.13687593 -0.37621015  0.10407971  0.7324834\n",
      "  0.6517809  -0.75942534 -0.15442745 -0.02792893]\n",
      "machine [-0.48818734 -0.28050557  0.7374693  -0.4949068   0.81296444  0.9190356\n",
      "  0.49818757 -0.97260904  0.672087    0.06502925]\n",
      "learning [-0.6131305   0.73140407  0.6111747   0.07433248  0.2040902   0.38182366\n",
      "  0.4017809  -1.102767   -0.05361607 -0.6599967 ]\n"
     ]
    }
   ],
   "source": [
    "# Extract wordlevel embeddings\n",
    "\n",
    "for word in word_lyrics:\n",
    "    if word not in wordModel.wv.vocab:\n",
    "        word_emb = wordModel.wv['I']\n",
    "        print(word, word_emb)\n",
    "    else:\n",
    "        word_emb = wordModel.wv[word]\n",
    "        print(word, word_emb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
